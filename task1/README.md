mkdir build
cd build
cmake ../task1  
cd ...\build\Debug
...\build\Debug> .\matrix_mul_original.exe
Time taken: 0.126000 seconds
...\build\Debug> .\matrix_mul_optimized.exe
Time taken: 0.094000 seconds

1. Результаты
   Время выполнения исходной программы: 0.126000 секунд
   Время выполнения оптимизированной программы: 0.094000 секунд

2. Задание 1: Сравнение оптимизированной и исходной программ
   Сравнение скорости вычислений:
   Время выполнения оптимизированной программы меньше по сравнению с исходной программой.
   Исходная программа: 0.126000 секунд
   Оптимизированная программа: 0.094000 секунд
   Таким образом, оптимизация программы с использованием shared memory позволила ускорить выполнение матричного умножения на GPU. Это объясняется тем, что при использовании shared memory данные загружаются в более быстрые области памяти, доступные для потоков в блоках, что уменьшает количество операций с глобальной памятью и повышает производительность. В отличие от исходной программы, где каждый поток обращается к глобальной памяти, что может быть медленным, оптимизированная программа делает меньше таких обращений.

3. Различия:
   Глобальная память против shared memory:

В исходной программе каждый поток читает данные напрямую из глобальной памяти, что вызывает значительные задержки при доступе к данным.
В оптимизированной программе используется shared memory, которая гораздо быстрее глобальной памяти. Это улучшает производительность, так как данные хранятся в области памяти, которая доступна только для потоков внутри одного блока, что минимизирует задержки при обращении к данным.
Процесс синхронизации потоков:

В оптимизированной версии программа использует синхронизацию с помощью \_\_syncthreads(), чтобы все потоки в блоке синхронизировались перед следующей итерацией вычислений. Это предотвращает ошибки из-за асинхронного выполнения потоков и помогает ускорить выполнение за счет более эффективного использования ресурсов.
Кэширование данных:

В оптимизированной версии, данные для каждого блока загружаются в shared memory, что значительно ускоряет доступ к данным и снижает нагрузку на глобальную память.

---

Отчет по результатам работы
Цель работы:
Целью лабораторной работы было изучение особенностей использования графических процессоров (GPU) для высокопроизводительных вычислений, а также оптимизация программы для матричного умножения с использованием CUDA.

Задание 1:
Разработка программы:

Программа была реализована для умножения двух матриц A и B, результат записывался в матрицу C. Программа использует технологию CUDA для параллельных вычислений на GPU.
Измерение времени работы программы:

Было измерено время выполнения исходной программы, и затем оптимизированной версии программы с использованием shared memory для ускорения доступа к данным.
Время выполнения исходной программы составило 0.126000 секунд.
Время выполнения оптимизированной программы составило 0.094000 секунд.
Оптимизация программы:

Оптимизация была достигнута за счет использования shared memory, которая позволяет ускорить доступ к данным для потоков в блоках. Это значительно снизило время выполнения программы.
Сравнение скорости вычислений:

Время выполнения оптимизированной программы на 25% быстрее, чем у исходной программы.
Это связано с улучшением производительности благодаря использованию shared memory и уменьшению количества обращений к глобальной памяти, что позволило ускорить вычисления.
Выводы:

Использование shared memory в CUDA позволило существенно ускорить выполнение программы. Основные различия между исходной и оптимизированной версиями заключаются в оптимизации доступа к данным и лучшем использовании ресурсов GPU.
Оптимизированная программа обеспечивает более высокую производительность, что является важным аспектом при работе с большими данными и сложными вычислениями на GPU.
